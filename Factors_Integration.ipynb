{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Factors Integration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roanacla/FactorsIntegration/blob/main/Factors_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXE3p9Gc8uVt"
      },
      "source": [
        "# Clone repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aScZNbVH-btB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dda1937-d5e5-4fd1-b929-4cc157118ad4"
      },
      "source": [
        "#Content Statistics\n",
        "!git clone https://github.com/Wayne122/Content_Statistics_Demo.git\n",
        "%cd /content/Content_Statistics_Demo\n",
        "!pip install -r requirements.txt\n",
        "!python3 -m spacy download en_core_web_lg\n",
        "\n",
        "#Sensationalism\n",
        "%cd /content/\n",
        "!git clone https://github.com/roanacla/nlp_sensationalism_scorer.git\n",
        "%cd /content/nlp_sensationalism_scorer/\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "#Context Veracity\n",
        "%cd /content/\n",
        "!git clone https://github.com/snarvekark/Veracity_Factor.git\n",
        "#!git clone https://github.com/roanacla/Veracity_Factor.git\n",
        "%cd /content/Veracity_Factor/\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Content_Statistics_Demo' already exists and is not an empty directory.\n",
            "/content/Content_Statistics_Demo\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (2.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 5)) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 5)) (2020.11.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "/content\n",
            "fatal: destination path 'nlp_sensationalism_scorer' already exists and is not an empty directory.\n",
            "/content/nlp_sensationalism_scorer\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (0.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.0.4)\n",
            "/content\n",
            "fatal: destination path 'Veracity_Factor' already exists and is not an empty directory.\n",
            "/content/Veracity_Factor\n",
            "Collecting git+https://github.com/abenassi/Google-Search-API (from -r requirements.txt (line 11))\n",
            "  Cloning https://github.com/abenassi/Google-Search-API to /tmp/pip-req-build-y2yc2h3h\n",
            "  Running command git clone -q https://github.com/abenassi/Google-Search-API /tmp/pip-req-build-y2yc2h3h\n",
            "Requirement already satisfied (use --upgrade to upgrade): Google-Search-API==1.1.14 from git+https://github.com/abenassi/Google-Search-API in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11))\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.6.3)\n",
            "Requirement already satisfied: selenium<3.0.0,>=2.44.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.53.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: vcrpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.1.11)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 4)) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from vcrpy->-r requirements.txt (line 6)) (1.12.1)\n",
            "Requirement already satisfied: yarl; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from vcrpy->-r requirements.txt (line 6)) (1.6.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from vcrpy->-r requirements.txt (line 6)) (3.13)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (0.3)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (0.35.1)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (4.2.6)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (6.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.6/dist-packages (from newspaper3k->-r requirements.txt (line 9)) (0.0.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 10)) (0.22.2.post1)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.6/dist-packages (from yarl; python_version >= \"3.6\"->vcrpy->-r requirements.txt (line 6)) (5.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from yarl; python_version >= \"3.6\"->vcrpy->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.6/dist-packages (from feedparser>=5.2.1->newspaper3k->-r requirements.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k->-r requirements.txt (line 9)) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k->-r requirements.txt (line 9)) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 10)) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 10)) (0.17.0)\n",
            "Building wheels for collected packages: Google-Search-API\n",
            "  Building wheel for Google-Search-API (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Google-Search-API: filename=Google_Search_API-1.1.14-cp36-none-any.whl size=607835 sha256=044e730ef33f0ae31d4b8a58a4746a8fee4bbacb1f75f6018203b8afa9fb474b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m5csdn90/wheels/9d/dd/52/f744758aa94909328835af5d6f1650c9c3d8cf2e6e8988767a\n",
            "Successfully built Google-Search-API\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of7JiFLhNVko"
      },
      "source": [
        "Note: After running the above cell, please restart the runtime. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwB3Wm2iAdHe"
      },
      "source": [
        "# Instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB9WH4E5AKtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a1f595-cd59-4154-f1b4-97fe377e8b6b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Content Statistics\n",
        "%cd /content/Content_Statistics_Demo/\n",
        "from Blastoff_Content_Statistics import BlastoffContentStatistics\n",
        "%cd /content/\n",
        "bcs = BlastoffContentStatistics()\n",
        "\n",
        "#Sensationalims\n",
        "%cd /content/nlp_sensationalism_scorer/\n",
        "from sensaScorer import SensaScorer\n",
        "sensa = SensaScorer()\n",
        "\n",
        "#Context Veracity\n",
        "%cd /content/Veracity_Factor/\n",
        "from context_veracity import Context_Veracity\n",
        "cv = Context_Veracity()\n",
        "\n",
        "%cd /content/nlp_sensationalism_scorer/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Content_Statistics_Demo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "/content\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Loading default pretrained model.\n",
            "/content/nlp_sensationalism_scorer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/Veracity_Factor\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/content/nlp_sensationalism_scorer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wb2vWNrAnbW"
      },
      "source": [
        "# Run Polinomial Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5s4Zc5783eW"
      },
      "source": [
        "def isFake(text):\n",
        "  accur = [0.26, 0.80, 0.50]\n",
        "  w = [float(i)/sum(accur) for i in accur]\n",
        "  prob = []\n",
        "\n",
        "  if text:\n",
        "    in_df = pd.DataFrame(data=[text], columns=['Statement'])\n",
        "    res_cs = bcs.predict(in_df).replace('pants-fire', 1.0).replace('false', 0.8).replace('barely-true', 0.6).replace('half-true', 0.4).replace('mostly-true', 0.2).replace('true', 0.0)\n",
        "    prob.append(w[0] * float(res_cs.iloc[0]))\n",
        "    \n",
        "  if text:\n",
        "    cv_val = cv.get_veracity_scores(text)\n",
        "    if cv_val == 1:\n",
        "      cv_final = 0.8\n",
        "    elif cv_val == 2:\n",
        "      cv_final = 0.4\n",
        "    elif cv_val == 3:\n",
        "      cv_final = 0.2\n",
        "    elif cv_val == 4:\n",
        "      cv_final = 1.0\n",
        "    elif cv_val == 5:\n",
        "      cv_final = 0.0\n",
        "    elif cv_val == 0:\n",
        "      cv_final = 0.6\n",
        "    prob.append(w[1] * float(cv_val))\n",
        "    \n",
        "  if text:\n",
        "    prob.append(w[2] * 0.75 * sensa.getScore(text))\n",
        "    \n",
        "\n",
        "  probTotal = sum(prob[0:len(prob)])\n",
        "  return probTotal"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92TztHp2csyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f13dc8b-b02b-4325-e51c-bfa74f370463"
      },
      "source": [
        "# result = isFake(\"Smartphones will become real personal computers\")\n",
        "# result = isFake(\"One America News Network, one of President Trump’s favorite media outlets, has been banned from posting new videos to YouTube for a week for spreading Covid-19 misinformation, YouTube said on Tuesday.\")\n",
        "result = isFake(\"Commander of the US Army: The elite of the US military will encircle China like the Soviet Union\")\n",
        "print(\"\\n\\n###### Result ######\")\n",
        "print(result)\n",
        "#if result > 0.5:\n",
        "#  print(\"FAKE NEWS ALERT!!!\")\n",
        "#else:\n",
        "#  print(\"NOT FAKE\")\n",
        "\n",
        "#Result with 6 labels\n",
        "if(result>0.8):\n",
        "  print(\"pants-on-fire\")\n",
        "elif(result<=0.80 and result>=0.64):\n",
        "  print(\"false\")\n",
        "elif(result <0.64 and result >=0.48):\n",
        "  print(\"barely-true\")\n",
        "elif(result<0.48 and result>=0.32):\n",
        "  print(\"half-true\")\n",
        "elif(result<0.32 and result>=(0.16)):\n",
        "  print('mostly-true')\n",
        "else:\n",
        "  print('true')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "###### Result ######\n",
            "1.9001602564102567\n",
            "pants-on-fire\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn8WEIUt6s4L"
      },
      "source": [
        "# Multi-modal model (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJsmILMq7FBv"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64NzeyZY7G6j"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=48, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBC9xY-lTRUy"
      },
      "source": [
        "##Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8YFFW3Z-4kN"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1sFMftHLILNfuS0kpTlsbUzWpSNs3WkeD\"})\n",
        "downloaded.GetContentFile('liar_plus_dataset.zip')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQfX4A6S-4k2"
      },
      "source": [
        "from zipfile import ZipFile"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw3M_EGd-4lC"
      },
      "source": [
        "with ZipFile('liar_plus_dataset.zip', 'r') as myzip:\n",
        "    train_data = myzip.open('train2.tsv')\n",
        "    test_data = myzip.open('test2.tsv')\n",
        "    valid_data = myzip.open('val2.tsv')\n",
        "\n",
        "train_p_df = pd.read_csv(train_data, sep='\\t', header=None).drop([0], axis=1).dropna(how='all')\n",
        "test_p_df = pd.read_csv(test_data, sep='\\t', header=None).drop([0], axis=1).dropna(how='all')\n",
        "valid_p_df = pd.read_csv(valid_data, sep='\\t', header=None).drop([0], axis=1).dropna(how='all')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zbqrs5fetVr"
      },
      "source": [
        "## Loading data v2\n",
        "\n",
        "## Delete this as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZelmdGQaT1MV"
      },
      "source": [
        "#from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "#gdd.download_file_from_google_drive(file_id='1Ic5xisbyKrm2e6P1prQQp3Hpxn4_vhVE',\n",
        "#                                  dest_path='/content/Veracity_main_new.csv',\n",
        "#                                  unzip=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztBY2N9_Ui5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e23df5-0839-4c4a-eacc-2cbee341c0c2"
      },
      "source": [
        "# %cd /content/\n",
        "# import pandas as pd\n",
        "# df_posts = pd.read_csv('/content/Veracity_main_new.csv', sep=',', error_bad_lines=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRahnd7he8e5"
      },
      "source": [
        "#Fixed in the new csv file, update link for csv file\n",
        "#df_posts.rename(columns={'title':'Statement'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWWRQTPGTU0_"
      },
      "source": [
        "## Rename the columns\n",
        "\n",
        "as the module requires the data to have \"Statement\" and \"Label\" to train. If you just want to inference, then \"Statement\" is enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yoFc0jqQZp-"
      },
      "source": [
        "train_p_df.rename(columns={2:'Label', 3:'Statement'}, inplace=True) ############# Uncomment this line\n",
        "test_p_df.rename(columns={2:'Label', 3:'Statement'}, inplace=True)  ############# Uncomment this line"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0C0IskXcfbr-",
        "outputId": "e473bf00-c9b1-4e11-ee82-feea038ba335"
      },
      "source": [
        "#df_posts = df_posts[df_posts['Label'] != 'full-flop'] ############################# Delete this cell\n",
        "#df_posts"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>title_count</th>\n",
              "      <th>veracity</th>\n",
              "      <th>Link</th>\n",
              "      <th>Date</th>\n",
              "      <th>Source</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A “system glitch” in Wisconsin that “swapped v...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>mber 10, 2020</td>\n",
              "      <td>Eric Trump</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Says Michigan Gov. Gretchen Whitmer said, “I w...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 4, 2020</td>\n",
              "      <td>Viral image</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“Trump supporters are blocking access to polli...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 3, 2020</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“USPS failed to deliver 27% of mail-in ballots...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 5, 2020</td>\n",
              "      <td>Bloggers</td>\n",
              "      <td>pants-fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stacks of bricks are showing up in Denver beca...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 3, 2020</td>\n",
              "      <td>Viral image</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>Queens voters received pre-marked ballots for ...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 1, 2020</td>\n",
              "      <td>Tweets</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>Philadelphia is “clouding the vote counting in...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 6, 2020</td>\n",
              "      <td>Ted Cruz</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>Pennsylvania “never opened.”</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/oct...</td>\n",
              "      <td>ober 22, 2020</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>Pennsylvania officials are “attempting to sile...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 2, 2020</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>barely-true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>“Wisconsin took a break, and when they returne...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.politifact.com/factchecks/2020/nov...</td>\n",
              "      <td>ember 5, 2020</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>pants-fire</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Statement  ...        Label\n",
              "0    A “system glitch” in Wisconsin that “swapped v...  ...        false\n",
              "1    Says Michigan Gov. Gretchen Whitmer said, “I w...  ...        false\n",
              "2    “Trump supporters are blocking access to polli...  ...        false\n",
              "3    “USPS failed to deliver 27% of mail-in ballots...  ...   pants-fire\n",
              "4    Stacks of bricks are showing up in Denver beca...  ...        false\n",
              "..                                                 ...  ...          ...\n",
              "140  Queens voters received pre-marked ballots for ...  ...        false\n",
              "141  Philadelphia is “clouding the vote counting in...  ...        false\n",
              "142                       Pennsylvania “never opened.”  ...        false\n",
              "143  Pennsylvania officials are “attempting to sile...  ...  barely-true\n",
              "144  “Wisconsin took a break, and when they returne...  ...   pants-fire\n",
              "\n",
              "[145 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbEHKIfiQ7xG"
      },
      "source": [
        "X_train = train_p_df.drop('Label', axis=1)\n",
        "y_train = train_p_df['Label']\n",
        "#X_test = test_p_df.drop('Label', axis=1)  ########################## Uncomment this line\n",
        "#y_test = test_p_df['Label']                ########################## Uncomment this line"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ArIeZLTJbf"
      },
      "source": [
        "X_train = X_train.rename(columns={9: 'barelytruecounts',\t10: 'falsecounts',\t11: 'halftruecounts', \t12: 'mostlytruecounts', \t13: 'pantsonfirecounts'})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQj6qH9C9t2a",
        "outputId": "3ab0e10b-7523-43d0-b26b-a4691fd8932b"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Content Statistics\n",
        "bcs_e_X_train = bcs.encode(X_train)\n",
        "\n",
        "# Context Veracity\n",
        "bcv_e_X_train = cv.liar_encode(X_train)\n",
        "# \"\"\"\n",
        "# bcv_tc = []\n",
        "# bcv_v = []\n",
        "# for s in X_train['Statement'].tolist():\n",
        "#     tc, v = cv.get_source_count_and_veracity(s)\n",
        "#     bcv_tc.append(tc)\n",
        "#     bcv_v.append(v)\n",
        "# bcv_d = {'title_count': bcv_tc, 'veracity': bcv_v}\n",
        "# bcv_e_X_train = pd.DataFrame(data=bcv_d)\n",
        "# \"\"\"\n",
        "\n",
        "# from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "# gdd.download_file_from_google_drive(file_id='1Pu0D6GffO5fBgXVCVnKcEAPr9lrbAYfK',\n",
        "#                                   dest_path='./bcv_encoder.zip',\n",
        "#                                   unzip=False)\n",
        "# archive = ZipFile('bcv_encoder.zip')\n",
        "# for file in archive.namelist():\n",
        "#     archive.extract(file, '/content/')\n",
        "# bcv_encoder = keras.models.load_model('/content/bcv_encoder')\n",
        "\n",
        "# bcv_e_X_train = bcv_encoder.predict(df_posts[['title_count', 'veracity']])\n",
        "\n",
        "# Sensationalism\n",
        "\n",
        "\n",
        "# Concatenate\n",
        "bcs_e_X_train = pd.DataFrame(data=bcs_e_X_train)\n",
        "bcv_e_X_train = pd.DataFrame(data=bcv_e_X_train)\n",
        "################################################################# Roger's encoded data\n",
        "\n",
        "e_X_train = pd.concat([bcs_e_X_train, bcv_e_X_train], axis=1) ## Also add it here\n",
        "\n",
        "# label\n",
        "d_y_train = pd.get_dummies(y_train)\n",
        "#e_X_test = bcs.encode(X_test)      ########################## Uncomment this line\n",
        "#d_y_test = pd.get_dummies(y_test)  ########################## Uncomment this line"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "1PsJoRjBiHrC",
        "outputId": "40786956-ec4a-469a-aa64-069fd23db6f8"
      },
      "source": [
        "e_X_train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.211837</td>\n",
              "      <td>4.940129</td>\n",
              "      <td>6.629362</td>\n",
              "      <td>9.050505</td>\n",
              "      <td>7.779742</td>\n",
              "      <td>5.332962</td>\n",
              "      <td>7.848826</td>\n",
              "      <td>2.241910</td>\n",
              "      <td>4.794161</td>\n",
              "      <td>4.960108</td>\n",
              "      <td>7.893267</td>\n",
              "      <td>10.353553</td>\n",
              "      <td>3.282789</td>\n",
              "      <td>6.091530</td>\n",
              "      <td>6.585247</td>\n",
              "      <td>7.080389</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.090829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.522613</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261555</td>\n",
              "      <td>1.204743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.557130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.858425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.685091</td>\n",
              "      <td>24.993542</td>\n",
              "      <td>8.810983</td>\n",
              "      <td>15.461455</td>\n",
              "      <td>18.635612</td>\n",
              "      <td>17.006910</td>\n",
              "      <td>12.319558</td>\n",
              "      <td>12.790240</td>\n",
              "      <td>13.600662</td>\n",
              "      <td>16.159719</td>\n",
              "      <td>24.423903</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.217363</td>\n",
              "      <td>10.460907</td>\n",
              "      <td>7.305364</td>\n",
              "      <td>15.332805</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.090829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.522613</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261555</td>\n",
              "      <td>1.204743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.557130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.858425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.717840</td>\n",
              "      <td>17.493813</td>\n",
              "      <td>21.625214</td>\n",
              "      <td>19.902271</td>\n",
              "      <td>16.396116</td>\n",
              "      <td>18.681688</td>\n",
              "      <td>9.622036</td>\n",
              "      <td>15.566667</td>\n",
              "      <td>16.872272</td>\n",
              "      <td>2.891501</td>\n",
              "      <td>19.356613</td>\n",
              "      <td>5.649988</td>\n",
              "      <td>12.538576</td>\n",
              "      <td>12.147779</td>\n",
              "      <td>13.704709</td>\n",
              "      <td>14.683739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>119.893852</td>\n",
              "      <td>65.078842</td>\n",
              "      <td>99.788956</td>\n",
              "      <td>43.281700</td>\n",
              "      <td>55.848087</td>\n",
              "      <td>71.463531</td>\n",
              "      <td>55.391323</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.219128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.260128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.647850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.525606</td>\n",
              "      <td>7.729620</td>\n",
              "      <td>12.469887</td>\n",
              "      <td>8.893852</td>\n",
              "      <td>4.215873</td>\n",
              "      <td>9.874452</td>\n",
              "      <td>8.484407</td>\n",
              "      <td>7.388212</td>\n",
              "      <td>3.339989</td>\n",
              "      <td>5.688490</td>\n",
              "      <td>9.019493</td>\n",
              "      <td>9.228015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.112736</td>\n",
              "      <td>0.272345</td>\n",
              "      <td>11.246957</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.152166</td>\n",
              "      <td>1.924122</td>\n",
              "      <td>3.005258</td>\n",
              "      <td>2.101192</td>\n",
              "      <td>2.430983</td>\n",
              "      <td>2.538757</td>\n",
              "      <td>0.613808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.866323</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.212578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.771477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.746030</td>\n",
              "      <td>6.962137</td>\n",
              "      <td>8.937541</td>\n",
              "      <td>10.381464</td>\n",
              "      <td>12.112238</td>\n",
              "      <td>9.934958</td>\n",
              "      <td>11.205393</td>\n",
              "      <td>5.096816</td>\n",
              "      <td>2.349538</td>\n",
              "      <td>8.490510</td>\n",
              "      <td>8.046689</td>\n",
              "      <td>6.587426</td>\n",
              "      <td>6.181075</td>\n",
              "      <td>9.011738</td>\n",
              "      <td>6.192536</td>\n",
              "      <td>5.939189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>119.893852</td>\n",
              "      <td>65.078842</td>\n",
              "      <td>99.788956</td>\n",
              "      <td>43.281700</td>\n",
              "      <td>55.848087</td>\n",
              "      <td>71.463531</td>\n",
              "      <td>55.391323</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.219128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.260128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.647850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10235</th>\n",
              "      <td>14.320944</td>\n",
              "      <td>9.797541</td>\n",
              "      <td>13.178794</td>\n",
              "      <td>9.223291</td>\n",
              "      <td>12.944340</td>\n",
              "      <td>8.568988</td>\n",
              "      <td>13.726955</td>\n",
              "      <td>5.387570</td>\n",
              "      <td>6.286666</td>\n",
              "      <td>6.619837</td>\n",
              "      <td>11.021467</td>\n",
              "      <td>10.266587</td>\n",
              "      <td>11.548634</td>\n",
              "      <td>5.286119</td>\n",
              "      <td>8.096164</td>\n",
              "      <td>9.989305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10236</th>\n",
              "      <td>7.283374</td>\n",
              "      <td>2.749019</td>\n",
              "      <td>13.989727</td>\n",
              "      <td>9.975429</td>\n",
              "      <td>7.808156</td>\n",
              "      <td>13.104544</td>\n",
              "      <td>15.540765</td>\n",
              "      <td>10.433757</td>\n",
              "      <td>7.728669</td>\n",
              "      <td>12.493134</td>\n",
              "      <td>12.843208</td>\n",
              "      <td>10.414503</td>\n",
              "      <td>15.673471</td>\n",
              "      <td>3.529014</td>\n",
              "      <td>12.453532</td>\n",
              "      <td>8.305533</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10237</th>\n",
              "      <td>14.668737</td>\n",
              "      <td>17.153057</td>\n",
              "      <td>18.849628</td>\n",
              "      <td>16.924801</td>\n",
              "      <td>16.816706</td>\n",
              "      <td>18.075964</td>\n",
              "      <td>23.956923</td>\n",
              "      <td>9.297574</td>\n",
              "      <td>15.733625</td>\n",
              "      <td>23.805601</td>\n",
              "      <td>15.216730</td>\n",
              "      <td>13.481300</td>\n",
              "      <td>15.414532</td>\n",
              "      <td>13.886168</td>\n",
              "      <td>24.709255</td>\n",
              "      <td>33.960194</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10238</th>\n",
              "      <td>8.766872</td>\n",
              "      <td>4.232331</td>\n",
              "      <td>16.911827</td>\n",
              "      <td>12.412843</td>\n",
              "      <td>10.520018</td>\n",
              "      <td>15.297036</td>\n",
              "      <td>18.743954</td>\n",
              "      <td>16.318684</td>\n",
              "      <td>6.590805</td>\n",
              "      <td>11.281427</td>\n",
              "      <td>15.499956</td>\n",
              "      <td>10.263979</td>\n",
              "      <td>20.670725</td>\n",
              "      <td>6.094724</td>\n",
              "      <td>11.486253</td>\n",
              "      <td>19.297413</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10239</th>\n",
              "      <td>21.133022</td>\n",
              "      <td>11.799815</td>\n",
              "      <td>20.579357</td>\n",
              "      <td>29.202312</td>\n",
              "      <td>13.692837</td>\n",
              "      <td>15.879474</td>\n",
              "      <td>31.298616</td>\n",
              "      <td>28.274752</td>\n",
              "      <td>7.714290</td>\n",
              "      <td>20.559336</td>\n",
              "      <td>15.310163</td>\n",
              "      <td>7.743214</td>\n",
              "      <td>0.138265</td>\n",
              "      <td>16.522406</td>\n",
              "      <td>19.244167</td>\n",
              "      <td>17.022907</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10240 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0          1          2   ...         13   14         15\n",
              "0       7.211837   4.940129   6.629362  ...   1.557130  0.0   0.858425\n",
              "1       8.685091  24.993542   8.810983  ...   1.557130  0.0   0.858425\n",
              "2      10.717840  17.493813  21.625214  ...  33.260128  0.0  80.647850\n",
              "3       7.525606   7.729620  12.469887  ...   0.212578  0.0   1.771477\n",
              "4       8.746030   6.962137   8.937541  ...  33.260128  0.0  80.647850\n",
              "...          ...        ...        ...  ...        ...  ...        ...\n",
              "10235  14.320944   9.797541  13.178794  ...        NaN  NaN        NaN\n",
              "10236   7.283374   2.749019  13.989727  ...        NaN  NaN        NaN\n",
              "10237  14.668737  17.153057  18.849628  ...        NaN  NaN        NaN\n",
              "10238   8.766872   4.232331  16.911827  ...        NaN  NaN        NaN\n",
              "10239  21.133022  11.799815  20.579357  ...        NaN  NaN        NaN\n",
              "\n",
              "[10240 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LOktPhYpJNEg",
        "outputId": "8cd12894-11a7-40bd-ba76-46b8d6777968"
      },
      "source": [
        "d_y_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>barely-true</th>\n",
              "      <th>false</th>\n",
              "      <th>half-true</th>\n",
              "      <th>mostly-true</th>\n",
              "      <th>pants-fire</th>\n",
              "      <th>true</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10237</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10238</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10239</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10240</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10241</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10240 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       barely-true  false  half-true  mostly-true  pants-fire  true\n",
              "0                0      1          0            0           0     0\n",
              "1                0      0          1            0           0     0\n",
              "2                0      0          0            1           0     0\n",
              "3                0      1          0            0           0     0\n",
              "4                0      0          1            0           0     0\n",
              "...            ...    ...        ...          ...         ...   ...\n",
              "10237            0      0          0            1           0     0\n",
              "10238            0      0          0            1           0     0\n",
              "10239            0      0          1            0           0     0\n",
              "10240            0      1          0            0           0     0\n",
              "10241            0      0          0            0           1     0\n",
              "\n",
              "[10240 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiZg0gMfAlem"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rne4ocZmAmlb",
        "outputId": "bac5a139-0110-44b2-ca83-d86f2881e3f7"
      },
      "source": [
        "model.fit(e_X_train, d_y_train,\n",
        "          epochs=1000,\n",
        "          batch_size=8,\n",
        "          shuffle=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-631895ed25a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 48 but received input with shape [None, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ9fE85Bk-3_"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASr6l59PlBaM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def MLPInference(title):\n",
        "    labels = ['barely-true', 'false', 'half-true', 'mostly-true', 'pants-fire', 'true']\n",
        "    X_train = pd.DataFrame(data=[title], columns=['Statement'])\n",
        "    # Content Statistics\n",
        "    bcs_e_X_train = bcs.encode(X_train)\n",
        "\n",
        "    # Context Veracity\n",
        "    bcv_e_X_train = cv.encode(X_train)\n",
        "\n",
        "    # Sensationalism\n",
        "\n",
        "\n",
        "    # Concatenate\n",
        "    bcs_e_X_train = pd.DataFrame(data=bcs_e_X_train)\n",
        "    bcv_e_X_train = pd.DataFrame(data=bcv_e_X_train)\n",
        "    ######################################################################### Roger's encoded data\n",
        "\n",
        "    e_X_train = pd.concat([bcs_e_X_train, bcv_e_X_train], axis=1) ########### Also add it here\n",
        "\n",
        "    pred = model.predict(e_X_train)\n",
        "\n",
        "    return labels[np.argmax(pred[0])]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "OTH7LqSulygC",
        "outputId": "6a3648cb-68a5-4809-a76f-5a8b170ba350"
      },
      "source": [
        "MLPInference('Media fawns over Biden\\'s Cabinet rollout, describes being rescued from this craziness by superheroes')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1Pu0D6GffO5fBgXVCVnKcEAPr9lrbAYfK into ./bcv_encoder.zip... Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3c8b49b0cbdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMLPInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Media fawns over Biden\\'s Cabinet rollout, describes being rescued from this craziness by superheroes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-0dff57cb478d>\u001b[0m in \u001b[0;36mMLPInference\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Context Veracity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbcv_e_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Sensationalism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Veracity_Factor/context_veracity.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mbcv_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/bcv_encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mbcv_e_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbcv_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_posts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'veracity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfiCGP9zNn4P"
      },
      "source": [
        "# How did we train our models?\n",
        "\n",
        "Han-Wei Lin [Content Statistics] -> https://colab.research.google.com/drive/1pOhnmm6X_J4t__2VxSISoDGTtWa_gZ5-?usp=sharing\n",
        "\n",
        "Roger Navarro [Sensationalism] -> https://github.com/roanacla/ML_Sensationalism/blob/main/Sensationalism.ipynb\n",
        "\n",
        "Sheetal Narvekar [Context Veracity] -> https://github.com/snarvekark/Veracity_Factor/blob/master/Context_Veracity_Main.ipynb"
      ]
    }
  ]
}